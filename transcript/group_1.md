# Automated transcript of Group Leader Summary

## What is this?
This is an automated transcript of the summary presented by a Group Leader to the other attendees of the Faculty Life Sciences away day on 25 June 2025.

## Group 1
* **Group Leader**: Ben Walker
* **Group Composition**: Alastair Yap, Ben Walker, Alice Fee, Claude Charest

## Questions (Topic A): Whom are we speaking to when we chat with a large language model?
* Are we actually speaking to a machine?
* Are we speaking to a single conversational counterpart, or to many, or to nobody at all?
* Are we speaking to ourselves?
* What effect does this have on human knowledge and public debate?

## Full Trascript
So we started off discussing what a machine is, and we discussed that it's determinist, it's predictable, and we use the example of a calculator. We also discussed that LLMs are getting to a point where they're now unpredictable, so with the same input you can get multiple outputs. the process is based on randomness, but we also posited that this is generally pseudo randomness.

What we discuss is that we are the ones that are predicting the next word. We then discussed, are we speaking to a single conversational counterpart and we thought about whether it's actually us this speaking and we're the ones that are add in our human framing. we considered other forms of technology, comparable to AI, such as Alexa, and actually, we came to the conclusion that there are no in current state, there are no existing forms of technology, that are comparable in terms of how we're engaging with this agent. We then considered a few examples, so we considered we're babies, or we get upset and sometimes frustrated, when we try and predict words as our brains are immature and undveloped, and we're unable to form more complex ideas, though, is our brain's develop.

We questioned whether we are just next prediction models ourselves. Yes, so in statistics, we also discussed that you have the real process and then the model and then you model this process. So the LLM is the model that's only in approximation.

We've considered the quote that we found useful, that all models are wrong, though some are useful. And we considered one more example, so the recent introduction by Apple to launch live translation to mediate conversations between different languages, we considered actually in this example, who are we really speaking to when we have an AI moderation? And finally, we considered to the question, are we speaking to ourselves that generally in our use of AI, we use LLMs as a useful tool to kind of self critique.

We weren't sure whether this meant that we were speaking to ourselves, so if we're all bouncing ideas off the same place, then will this mean that we will end up reaching the same destination? And we came to the conclusion that actually we don't think this is currently the case, because we'll be providing both our own judgement and our own critical thinking to the the problem. Yeah, I was everything.

Thank you.